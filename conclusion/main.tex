% Vi foretog indgående analyse af eksisterende løsninger på Approximate SS problemet, der viste at advancerede teknologier som præsenteret af Dahlgaard et al. osv er teoretisk overlegende hvis man er villig til at foretage nogle specifikke tradeoffs.
% En praktisk implementation viste sådan og sådan med denne specificitet ud fra sådanne benchmarks.
% Vores konklusioner er bla bla, og det indikerer bla bla.
% Ydergående undersøgelser kan undersøge ligende og lignende.
\section{Conclusion}
An in-depth analysis of existing solutions to the Approximate Similarity Search Problem described how many existing solutions utilize sketching to achieve a low query time with a constant error probability. In the case that one wants a sub-constant error probability, a possible solution by \citet{fast-similarity-search} was presented that can reduce the query time even further.

An important part of this optimization relies in being able to quantify the accuracy of a collection of data structures very efficiently, which is done in part by calculating the cardinality of a sequence of bit-strings packed into a list of words. \citet{fast-similarity-search} presents an algorithm to do this in parallel, which reduces the total query time to be sub-linear to the amount of sets in the corpus.\\
An analysis of the bit-counting algorithm shows its correctness with a few modifications alongside a theoretical running time which matches \cite{fast-similarity-search}. Benchmarks performed on an actual implementation tells otherwise however, showing that the word parallelism used to achieve a low amortized cost actually is hard to match simpler algorithms in practice when used on standard word sizes. Further research might focus on benchmarking the algorithm on more specialized hardware, although rewriting the implementation seems to be non-trivial.
