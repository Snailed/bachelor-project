\section{Parallel Bit Counting}
In the same article where \citet{fast-similarity-search} presents the improvements for algorithms with an $\varepsilon = o(1)$ error probability, a parallel algorithm to compute the cardinality of a sequence of bit-strings packed into sequence of words is also presented. It is only described by recurrences, and omits implementation details. I will try to describe the same algorithm in a much simpler fashion and prove its correctness and time complexity while doing it. This means that this section is my own interpretation of the algorithm, proofs and analysis described in \cite{fast-similarity-search}.\\
For a word $t$ with word size $w$ packed with $w/d$ bit-strings for some $d \leq w$, a naive algorithm to perform bit-counting could be described like in algorithm \ref{alg:naive-cardinality}.
\begin{algorithm}[H]
\caption{A naive linear time algorithm}\label{alg:naive-cardinality}
\begin{algorithmic}[1]
\Function{Cardinality}{$t$}
\State $S \gets \{\}$
\For{$j \in [w/d]$}
\State $x \gets 0$
\For{$i \in [d]$}
\State $x \gets x + ((t \ll j \cdot d) \gg i) \land 1$
\EndFor
\State $S \gets S \cup \{ x \}$
\EndFor
\State \Return $x$
\EndFunction
\end{algorithmic}
\end{algorithm}
This algorithm trivially runs in linear time to the word size\footnote{For the rest of this project, it is assumed that $w$ is a power of 2.} $w$ of the input word $t$. For $n$ words of size $w$, this algorithm runs in $O(n d \frac{w}{d}) = O(n w)$ time.
\citet{fast-similarity-search} presents two improvements to this: The first will improve the running time to $O(n\log(d))$ by utilizing a divide-and-conquer technique and the second to $O(n + \log(d))$ time by introducing parallelism. % TODO: FIX THIS
\subsection{Divide-and-Conquer}
To explain how divide-and-conquer methods can be used to improve running time, we must first introduce a word sized bit mask from \cite{fast-similarity-search} that is defined like so (in binary):
$$m_{i,j} = \underbrace{0\dots 0}_{2^{j}-2^{i}}\underbrace{1\dots 1}_{2^i}\dots\underbrace{0\dots 0}_{2^{j}-2^{i}}\underbrace{1\dots 1}_{2^i}$$
where $j > i$ and $j$ and $i$ are non-negative integers. The notation $m_{i}$ is a shorthand for $m_{i, i+1}$ and indicates a mask with an equal amount of 1's and 0's. By computing $t \land m_{i,j}$ for some word $t$ and some integers $i, j$, we can replace every other sub-string of size $2^j-2^i$ in the bit-string with 0's. This will be described as \textit{isolating} segments of size $2^i$.\\
We will use this in the following operation:
\begin{equation}
    T(t, m, k) = (t\gg k) \land m
\end{equation}
This operation isolates the segments indicated by the bit-mask starting from the $k$th position of the word $t$. This is useful for partitioning a bit-string, since any word now can be described as
$$t=T(t, m_i, 0) + (T(t, m_i, 2^i) \ll 2^i)$$
Notice that even though we use addition, overflows are impossible since the segment pattern of $T(t, m_i, 0)$ and $(T(t, m_i, 2^i) \ll 2^i)$ do not overlap.\\
The algorithm to calculate the cardinality of a single bit-string in a word $t$ can then be described like in algorithm \ref{alg:divide-and-conquer-cardinality}
\begin{algorithm}[H]
\caption{A divide-and-conquer approach}\label{alg:divide-and-conquer-cardinality}
\begin{algorithmic}[1]
\Function{Cardinality}{$t$}
\For{$i \in [\log_2(d)]$}
\State $t \gets T(t, m_i, 0) + T(t, m_i, 2^i)$
\EndFor
\State \Return $t$
\EndFunction
\end{algorithmic}
\end{algorithm}
The simplest way to gain intuition of this algorithm is to prove it. A loop-invariant is presented like so:
\begin{invariant}
\label{thm:divide-invariant}
At the beginning of the $i$th iteration of the algorithm, the word $t^{(i)}$ can be regarded as consisting of $w/2^i$ bit-string-segments of size $2^i$, that represents the cardinality of the corresponding segments of the word $t^{(0)}$.
\end{invariant}
\begin{proof}
    \textbf{Base case}: When $i=0$, then each bit-string of size $2^0=1$ in $t^{(0)} = t$ will be $1$ if the bit is $1$ and $0$ if the bit is $0$. This proves our base case. \\
    \textbf{Induction step}:
    At step $i$, invariant \ref{thm:divide-invariant} states that the word $t^{(i)}$ contains $\frac{d}{2^i}$ segments of size $2^i$. The operation $T(t, m_i, 0)$ will then isolate exactly every other segment of size $2^i$. The operation $T(t, m_i, 2^i)$ will isolate the remaining segments and bit-shift them such that the segments align with the segments isolated by $T(t, m_i, 0)$.\\
    By adding $T(t, m_i, 0)$ and $T(t, m_i, 2^i)$ together, every pair of overlapping segments will be added together to form a new segment of double the size. Invariant \ref{thm:divide-invariant} states that each segment of $T(t, m_i, 0)$ and $T(t, m_i, 2^i) \ll 2^i$ represents the cardinality of a corresponding segment in $t^{(0)}$. Since the cardinality of a bit-string is equal to the sum of its parts, we can interpret each new segment as the cardinality of the corresponding two previous segments combined. Therefore, at the end of the $i$th iteration of the for-loop, the word $t$ can be interpreted as consisting of bit-string segments of size $2^{i+1}$, where each bit-string-segment represents the cardinality of the corresponding bit-string segments of $t^{(0)}$.
    %Since the cardinality of a combined bit-string is equal to the cardinality of its parts, we can divide all of the segments into pairs of size $2^{i+1}$ and add them together to form the new pair, which is done by the operation $T(w, m_i, 0) + T(w, m_i, 2^i)$ in constant time if the masks are pre-computed. 
    % This operation works because $T(w, m_i, 0)$ isolates every other segment of size $2^i$ starting from the first segment and $T(w, m_i, 2^i)$ isolates every other segment of size $2^i$ starting from the second segment.\\
\end{proof}
When the algorithm terminates after $\log_2(d)$ iterations, the segments will have size $2^{\log_2{(d)}} = d$ and thus span the entire size of the original bit-string, which means that we have the bit-count of the original bit-string. If $m_{i}$ for $i\in [\log_2{(d)}]$ is pre-computed, then each iteration can be performed in constant time.
If the word $t$ instead contains a sequence of $m=w/d$ bit-strings of size $d$, the cardinality of all of the $m$ bit-strings can be calculated in $O(\log_2{(d)})$ time.
If one has $n$ of such words, the running time will therefore be $O(n\log_2{(d)})$.
It is to be noted that this algorithm returns a word $t^{(\log_2{d})}$ where the cardinalities of each of the bit-strings from $t^{(0)}$ are embedded inside the word.
\subsubsection{Example}
Given a word $t^{(0)}=1101011001010010_2$ containing 1 bit-string, we can run the algorithm by hand to find the cardinality. Due to invariant \ref{thm:divide-invariant}, we can regard $t^{(0)}$ as consisting of $w/2^0=16$ sections of size $2^0=1$ as marked by colors:\\
$$t^{(0)}=\color{blue}1\color{red}1\color{blue}0\color{red}1\color{blue}0\color{red}1\color{blue}1\color{red}0\color{blue}0\color{red}1\color{blue}0\color{red}1\color{blue}0\color{red}0\color{blue}1\color{red}0_{\color{black}2}$$
At the beginning of the first iteration, we can calculate $m_0$ to be $0101010101010101_2$. This means that 
$$T(t^{(0)}, m_0, 0)=0101010001010000_2$$ 
and $$T(t^{(0)}, m_0, 2^0)=0100000100000001_2$$
We can add them together to get $t^{(1)}$:
$$t^{(1)}=\color{blue}10\color{red}01\color{blue}01\color{red}01\color{blue}01\color{red}01\color{blue}00\color{red}01_{\color{black}2}$$
Notice that each section has now doubled in size. Due to invariant \ref{thm:divide-invariant}, each section represents the bit-string cardinality of the corresponding section of $t^{(0)}$. For example, the least significant section $\color{red}01\color{black}_2 = 1_{10}$ represents that the there is 1 bit set in the 2 least significant bits of $t^{(0)}$ (which we can see is true). Continuing the algorithm, we get:
$$t^{(2)}=\color{blue}0011\color{red}0010\color{blue}0010\color{red}0001\color{black}_2$$
$$t^{(3)}=\color{blue}00000101\color{red}00000011\color{black}_2$$
$$t^{(4)}=\color{red}0000000000001000\color{black}_2 = 8_{10}$$
The algorithm has now terminated, and we can see that $t^{(0)}$ contains 8 bits set, which we can see is true.
If instead, we regarded the word $t^{(0)}$ as containing two bit-strings of size $8$ each, then we could stop the algorithm after iteration $i=2$, where $t^{(3)}$ contains the bit-string cardinalities of each of the two sections. Then we could see that the first bit-string contains 5 bits set, and the second contains 3 bits set.

% \input{tikz/example1}
\subsection{Parallelism}
To introduce parallelism into the algorithm, we must first realize the following: When two segments of $2^i$ bits gets combined, they will not need all of the $2^{i+1}$ bits to represent their sum. It is actually such that the bits used at iteration $i$ is exactly $i+1$.
\begin{invariant}
    \label{thm:amount-of-bits}
    At the end of the $i$th iteration of algorithm \ref{alg:divide-and-conquer-cardinality}, the amount of bits set in a given segment of a word $t^{(i+1)}$ is at most $i+1$.
\end{invariant}
\begin{proof}
    At iteration $i$, the algorithm will add two words where each bit-string-segment has a size of $2^i$ bits. In the worst case, where all bits are set, each segment in $t^{(i)}$ will have the value $2^{i+1}-1$, which means that each segment in $t^{(i+1)}$ will have the value $2^{i+1}-1 + 2^{i+1}-1 = 2(2^{(i+1)} - 1)$. To find out how many bits is needed to represent the given number, we can calculate $\log_2$ of the expression and round down: $\lfloor \log_2{(2(2^{(i+1)} - 1))}\rfloor=\lfloor 1 + \log_2{(2^{(i+1)}-1)} \rfloor = 1+\lfloor \log_2{(2^{(i+1)}-1)}\rfloor = i + 1$. Therefore, at the end of the $i$th iteration, each segment can only have $i+1$ or fewer bits set.
    %If it is true at iteration $i$, then at iteration $i+1$ the algorithm will add two words of size $i+1$ which creates a word of size $i+2$, which fulfills the loop invariant.
\end{proof}
Now, we will introduce a function $l(i)$, which produces the smallest non-negative integer such that $2^{l(i)} \geq i + 2$. We can now use the bit-mask $m_{l(i), i+1}$ instead of $m_{i}$, since the segments are guaranteed to be strictly smaller than $2^{l(i)}$. At the end of each iteration, there will be a sequence of $2^{(i+1)-l(i+1)}$ unused bits between each segment, since each segment will have size $2^{(i+1)}$ (invariant \ref{thm:divide-invariant}) but at most use $i+1$ bits (invariant \ref{thm:amount-of-bits}). In the case that $2^{(i+1) - l(i+1)} \geq 2^{l(i+1)}$, this unused sequence can contain a segment from an entirely different word (note that this happens when $l(i)=l(i+1)$). Algorithm \ref{alg:parallel-d-and-c} uses this to efficiently compute the cardinality of all the words in a set $S = \{t_0, \dots t_{n-1}\}$.
\begin{algorithm}[H]
\caption{A parallel divide-and-conquer algorithm}\label{alg:parallel-d-and-c}
    \begin{algorithmic}[1]
        \Function{Compute}{$S$, $d$} \Comment{$S$ is the input set, $d$ is the word size}
            \State $n \gets S.length$
            \For{$i \in [\log_2(d)]$}
                \State $k' \gets \{\}$
                \State $t \gets \{\}$
                \For{$t \in S$}
                    \State $k' \gets k' \cup \{T(t, m_i, 0) + T(t, m_i, 2^i)\}$
                \EndFor
                \If{$i < 2$}
                    \State $S \gets k'$
                \Else
                \If{$l(i) = l(i+1)$ AND $S.length > 1$}
                    \For{$j \in [\lceil S.length / 2 \rceil]$}
                    \State $t \gets t \cup \{k'_{2j} + (k'_{2j+1} \ll 2^i)\}$ % TODO: Er det l(i) eller l(i+1)?
                    \EndFor
                \Else
                    \For{$j \in k'$}
                        \State $t \gets t \cup \{T(k'_{j}, m_{l(i)}, 0) + (T(k'_{j}, m_{l(i)}, 2^{l(i)}) \ll 2^{i})\}$
                    \EndFor
                \EndIf
                \State $S \gets t$
                \EndIf
            \EndFor
            \State $S' \gets \{\}$
            \For{$j$ in $[S.length]$} \Comment{For every word in the final set}
            \For{$k$ in $[2^{l(\log_2(d))}]$} \Comment{For every original bit-string embedded in $S_j$}% TODO: Research this!
                \State $S' \gets S' \cup \{T(S_j, m_{l(\log_2(d)), \log_2(d) + 1}, k\cdot 2^{l(\log_2(d))})\}$
                \EndFor
            \EndFor
            \State \Return $S'$
        \EndFunction
    \end{algorithmic}
\end{algorithm}
This algorithm is quite a bit more complex than the first one, and to prove it we need some more terminology.\\
When we pack the words $t_0, \dots, t_{2^{i-l(i)}-1}$ into a word $t$, we say that $t$ is $i$-packed. This means one can extract all $2^{i-l(i)}$ different words by performing the operation:
\begin{equation}
    \label{eq:extract-from-embed}
t^{(i)}_j=T(t, m_{l(i), i+1}, j\cdot 2^{l(i)})
\end{equation}
for all $j\in [2^{i-l(i)}-1]$.
The point of the algorithm is to ensure that after every step of the algorithm that every word in $S$ is $(i+1)$ packed. When the first loop of the algorithm terminates at $i=\log_2(d)-1$, then every word will be $\log_2(d)$-packed, which means that it fits $2^{\log_2(d)-l(\log_2(d))}$ words. When working with 64-bit words, this will result in $2^{6-3}=8$ words per packed word.
\begin{invariant}
    At the end of the $i$th iteration of the first loop of the algorithm, every word in $S$ will be $(i+1)$-packed for any $i \geq 1$
\end{invariant}
\begin{proof}
    First, the first two iterations of the loop are run, such that $i=1$. During the first two iterations of the loop, no words are combined since it just uses the naive algorithm, which upholds the invariant because any $2$-packed words embeds $2^{0}=1$ of the original words.\\
    For any iteration where $i\geq 2$, one out of two things can happen. Either, $l(i+1) = l(i)$ (we do not need more bits to describe each segment), or $l(i + 1) = l(i) + 1$ (we need twice the amount of bits to describe each segment).\\
    In the first case, we will combine the words using bit-shifting. Since every word in $k'$ uses the same amount of bits to represent each segment even though we just combined segments when creating $k'$, there must be an empty space of at least size $2^{l(i+1)}$ in every segment. We can fill out that empty space by adding another word bit-shifted by a factor of 2.
    Now, the amount of words embedded is equal to the sum of both of its parts (i.e. has doubled). This upholds the loop invariant since any $(i+1)$-packed word must have twice the amount of words embedded than a $i$-packed word if $l(i+1) = l(i)$ by definition.\\
    In the second case, $l(i + 1) = l(i) + 1$. In this case, we need to relocate our segments that actually use $2^{l(i)}$ bits so they fit into the segments of size $2^i$ bits that were created when creating $k'$.
    The same amount of words have been embedded into each words as before, but as $l(i+1) = l(i) + 1$ a $(i+1)$-packed word should only embed the same amount of words as a $i$-packed word, which upholds the invariant.
    Furthermore, since we relocated the segments, we can now still extract each original word by performing the operation in equation \ref{eq:extract-from-embed}.\\
    The for-loop will terminate when $i = \log_2(d) - 1$, from which each word in $S^{(\log_2(d))}$ will embed $2^{\log_2(d)-l(\log_2(d))}$ of the words from $S^{(0)}$.
\end{proof}
When the first for loop has finished, each $S'_i$ for $i\in [n]$ will contain words with embedded cardinalities due to invariant \ref{thm:divide-invariant}, just like algorithm \ref{alg:divide-and-conquer-cardinality}.

\subsubsection{Example}
For the first two iterations of the first for-loop, the algorithm works exactly as algorithm \ref{alg:divide-and-conquer-cardinality}. When $i=2$, lines $17-19$ are hit for the first time, but since the words are $(3)$-packed, there will only be $2^{2-2}=1$ words from $S^{0}$ embedded in each word in $S^{(2)}$. This results in the operation at line $18$ leaving $k'$ unchanged.\\
When $i=3$, the lines $12-16$ are hit for the first time. This results in words getting pairwise combined. Here is an example of how words in $k'$ for some set $S^{(3)}$ can get merged together (segments of size $2^{l(i)}$ are colored):
$$k'=$$
$$\{00000000 \color{red}00001111 \color{black}00000000 \color{red}00001001\color{black}_2, \color{black}0000 0000 \color{blue}0000 1010\color{black}00000000\color{blue}00010000\color{black}_2\}$$
$$S^{(4)}=\{\color{blue}00001010\color{red}00001111\color{blue}0001 0000 \color{red}0000 1001\color{black}_2\}$$
Since lines 6-8 of the next iteration of the algorithm will combine segments of size $l(4) = l(3)$, $k'$ will be:
$$k'=\{\color{black}0000000000000000\color{blue}0001 1010 \color{red}0001 1000\color{black}_2\}$$
After this iteration, the main for-loop terminates and the final set $S'$ can be constructed to the following:
$$S'=\{0000000000000000 00000000 \color{red}00011000\color{black}_2, 0000000000000000 0000 0000 \color{blue} 0001 1010\color{black}_2\}$$
$$=\{ 24_{10}, 26_{10} \}$$
If $d=w$, then this means that $S^{(0)}_0$ should contain 24 bits set and $S^{(0)}_1$ should contain 26 bits set.
% Since this algorithm works best when word sizes are large (e.g. $\log_2(d) > 6$), it can be very cumbersome to hand-run examples. Therefore, this example only uses $d=16$, but still shows how the algorithm can merge multiple words together which also applies for larger word sizes.\\
% If we are given set $S^{(0)} = \{w_0^{(0)}, \dots w_3^{(0)}\}$ defined as
% $$S^{(0)} = $$
% $$\{1101101010110010_2, 0110101111100101_2, 1110101000101010_2, 0011101010101110_2 \}$$
% then we can calculate the cardinality of each word in $S^{(0)}$. First, we run through the first two iterations of the algorithm, which are the same as in algorithm \ref{alg:divide-and-conquer-cardinality}.
% $$S^{(1)} = $$
% $$\{1001010101100001_2, 0101011010010101_2, 1001010100010101_2, 0010010101011001_2 \}$$
% $$S^{(2)} = $$
% $$\{0011001000110001_2, 0010001100110010_2, 0011001000010010_2, 0010001000100011_2 \}$$
% Then we reach $i=2$ (the third iteration of the algorithm). Since $l(2) = 2$ and $l(3) = 3$, we enter the branch at line 17-19 where we calculate $t_0$ and $t_1$. Since every word is $i = 2$ packed at this point, each word $w \in k'$ will only consist of segments from 1 of the original words, which means that the operation on line $18$ does nothing. Therefore
% $$S^{(3)} = $$
% $$\{0000010100000100_2, 0000010100000101_2, 0000 0101 0000 0011_2, 0000 0100 0000 0101_2 \}$$
% For the last iteration of the algorithm, first $k'$ is calculated (colored for clarity):
% $$k'= $$
% $$\{\color{red}00000000 00001001\color{black}_2, \color{blue}0000 0000 0000 1010\color{black}_2, \color{green}0000 0000 0000 1000\color{black}_2, \color{orange}0000 0000 0000 1001\color{black}_2\color{black}\}$$
% Then we enter line 12-16 of the for-loop which combines the words. Therefore we end up with:
% $$S^{(4)}=\{\color{blue}0000 1010 \color{red}0000 1001\color{black}_2, \color{orange}0000 1001 \color{green}0000 1000\color{black}_2\}$$
% Now the for-loop terminates.
\subsection{Discrepancies}
In the original article, combining the sections of a word (like we do in algorithm \ref{alg:divide-and-conquer-cardinality} and on line 7 and 14 in algorithm \ref{alg:parallel-d-and-c}) is done with the following operation:
$$t^{(i+1)}=T(T(t^{(i)}, m_i, 0) + T(t^{(i)}, m_i, 2^i), m_{i+1}, 0)$$
Here, the algorithm is described as a recurrence, where $t^{(i)}$ is the word $t$ after $i$ iterations. This definition is troublesome since the outermost call to $T$ causes information loss. A counter-example to this is just the word $t^{(0)} = 1111_2$. We can see that this word contains 4 bits set. Using this operation, we can see that 
$$t^{(1)}=T(T(1111_2, 0101_2, 0) + T(1111_2, 0101_2, 2), 0011_2, 0) = 0010_2$$
The outermost application of the bit mask means that we lose information about the two most significant bits of $t$. If we were to calculate $t^{(2)}$ and thus let the algorithm terminate, we would only have counted half of all the bits!\\
This is simply solved by removing the outermost call to $T$, since no information will be lost and invariant \ref{thm:divide-invariant} will apply.\\
Another issue with the original article is that the order of the cardinalities in the final set $S'$ is not consistent with the order of the original set $S^{(0)}$.
When the algorithm shifts the sections in each word in line 17-19 of the algorithm, every other section gets shifted $2^i$ bits to the left. 
When the algorithm has terminated, the cardinalities of $S^{(0)}_i$ might be contained at a later position in $S'_j$ than $S^{(0)}_{i+1}$ for some $i\in [n]$. The original paper by \citet{fast-similarity-search} does not mention this, and it is not said whether this affects the criteria of correctness, but for any practical usage, this does seem like it could be an issue. 

This is only a problem when $\log_2(d) \leq 7$, since line 17-19 only runs when $l(i + 1) = l(i) + 1$ and $i > 2$ (it is also run when $i=2$, but causes no problem since no words have been packed yet, which means that they will not get shifted).
%If we imagine a set $P$ which contains disjoint subsets of $S'$ such that the set $P_i$ contains the cardinalities of the bit-strings in the set $S^{(0)}_i$ for any $i\in [n]$ in the order that they appear in $S'$, then the following formula calculates an index $j$ from $i$ when $d=128$.\\
%$$
%j(i) =
%\begin{cases}
%    (i \gg 1) + ((i \gg 3) \ll 2) & \textrm{if }i \& 1 = 0 \\
%    (i \gg 1) + 4 + ((i \gg 3) \ll 2) & \textrm{otherwise}
%\end{cases}
%$$
%\begin{proof}
%When $i=6$, every word in $S$ contains $2^{6-3}=8$ words. Before lines 17-19 are run, each word from the original set is described as at least one bit-string segment of $2^{l(6)}=8$ bits each.
%Lines 17-19 then takes every other segment and shifts it $2^6=64$ bits to the left. Since this is the last iteration of the algorithm, the for loop in lines 25-29 gets run immediately after, which extracts each segment into $S'$ in the order of the least significant first for each word.\\
%This means that the bit-strings of every other word from the original set will be shifted 4 indices later in $S'$, since 64 bits can contain $64/8=8$ words and half of them get shifted as well. 
%%When one calculates $j(i)$, and i is less than 8 and i is even, then we know that it has not been shifted. This means that the index we need to calculate must be one of the first 4 indices of $S'$. Since the order of the even elements of the original set is preserved, then we can just calculate half of the index to find 
%The calculation presented to find $j(i)$ has two branches: one branch if $i$ is even and one if $i$ is uneven. If $i$ is even, $j(i)$ can be found by calculating $(i \gg 1) + ((i\gg 3) \ll 2)$ (as is done using bit-shift calculation). If $i$ is odd, then this calculation is just offset by 4.
%This works, because the shifting makes such that $S'$ contains series of the first 4 even indices of the original set, then the first 4 odd indices, then the next 4 even indices and so on. The $(i \gg 3)$ calculates the index of which of these series that $i$ is found in, and by shifting it 2 bits to the left, we effectively multiply this index by 4 to find which series that our number is in. Then we calculate which of these 4 indices in the series that correspond to our number by calculating $(i \gg 1)$. If $i$ is odd, we will have to add 4, since we are interested in the odd indices.
%%This works because $(i \gg 8)$ calculates which word in the final , which is multiplied by 4.
%\end{proof}
%If we were to use a word size that is large enough such that lines 17-19 get run again, then we would have to find a more complex computation to find the correct index. This will only happen when $d\geq16384$, so we can safely assume that this will not be relevant in the near future unless new computers get invented with such large word sizes.
\subsection{Time Complexity Analysis}
We can now move on to showing the time complexity of the algorithm. 
First, we can try to find the running time of the first for-loop. At each iteration $i$, we will describe the amount of elements in $S^{(i)}$ as $n^{(i)}$ with $n=n^{(0)}$. We can then describe $n^{(i)}$ like so:
\begin{equation}
    n^{(i)}=
    \begin{cases}
        n & \textrm{if } i \leq 1  \\
        \lceil \frac{n}{2^{i-l(i)}} \rceil & \textrm{otherwise}
    \end{cases}
\end{equation}
which means that the first for-loop in total takes
$$\sum_{i=0}^{\log_2{(d)}}n^{(i)}$$
$$=2n+\sum_{i=2}^{\log_2{(d)}} n^{(i)}$$
$$=2n + \sum_{i=2}^{\log_2(d)}\lceil \frac{n}{2^{i-l(i)}} \rceil$$
Since the last loop iterates over every element of the original set, it must take $O(n)$ time. We can now derive the total running time:
$$O(n) + 2n + \sum_{i=2}^{\log_2(d)}\lceil \frac{n}{2^{i-l(i)}} \rceil$$
$$=O(n) + \sum_{i=2}^{\log_2(d)}\lceil n2^{l(i)-i} \rceil$$
$$\leq O(n) + \sum_{i=2}^{\log_2(d)}(n 2^{l(i)-i} + 1)$$
$$\leq O(n + \log(d)) + n\sum_{i=2}^{\log_2(d)}2^{l(i)-i}$$
Now we use the fact that $l(i)$ is always the smallest number that satisfies $2^{l(i)} \geq i + 2$. Since it is the smallest number, then $2^{l(i)} < 2(i+2)$, which can be proved by contradiction: $2^{l(i)} \geq 2(i+2) \implies 2^{l(i)-1} \geq i+2$, which shows that there is a number that is 1 smaller than $l(i)$ that upholds the bound $2^{l(i)} \geq i + 2$. Therefore $2^{l(i)} < 2(i+2)$. We can now use this fact:
$$\leq O(n + \log(d)) + n\sum_{i=0}^{\infty}\frac{2(i+2)}{2^{i}} = O(n+\log(d))$$
The running time of the algorithm can therefore be bound to $O(n + \log(d))$.
