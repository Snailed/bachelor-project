\subsection{Trivial Solution}
The most obvious solution is to compare each element in each set $A\in \mathcal{F}$ with each element in $Q$ to calculate the size of the intersection $|A\cap Q|$ and union $|A \cup Q|$. This solution will always give the correct answer, and query in $O(n|Q|\max_{A\in \mathcal{F}}|A|)$ time trivially, but suffers from the \textit{curse of dimensionality}: The running time is proportional to the dimensionality of the corpus, which can be a big bottleneck in terms of performance.
When working with high-dimensional data sets like often seen in text processing, this can have huge consequences. \citet{li2011hashing} has shown that it is easy to reach a dimensionality upwards of $|A|=2^{83}$ when using \textit{5-shingles} (5 contiguous words) of the 10,000 most common English words.
This algorithm is guaranteed to return the set $S=\arg\max_{A \in \mathcal{F}}J(Q,A)$ on every query. The next algorithm can query much faster than this by relaxing this condition: If we allow pre-processing the data and relax the requirement of finding an exact match by considering the approximate similarity search problem instead, we can create so-called sketches of the data set before querying. This sketching strategy can drastically reduce the query time.
