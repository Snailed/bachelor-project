\subsection{Parallel Bit Counting}
To be able to filter bad matches from good matches, we can use the 1-bit minwise hashing trick to pack the results of multiple subexperiments into one word, which by comparing the bit-wise cardinality (amount of bits set in a bit vector) of two words approximates the similarity between the two. % TODO: Research this!
One of the main techniques behind achieving an efficient run time of this method requires computing the cardinality of a bit vector efficiently. \citet{fast-similarity-search} presents a parallel algorithm to perform this but does neither describe any implementation details and has an unnecessarily complicated proof. I will try to describe the same algorithm in a much simpler fashion and prove its correctness and run time while doing it.
A naive algorithm to do this could be described like in algorithm \ref{alg:naive-cardinality}.
\begin{algorithm}[H]
\caption{A naive linear time algorithm}\label{alg:naive-cardinality}
\begin{algorithmic}
\Function{Cardinality}{$w$, $d$} \Comment{$w$ is the input word, $d$ is the word-size}
\State $x \gets 0$
\State $i \gets 0$
\While{$i \leq d$}
\State $x \gets x + (w \gg i) \land 1$
\State $i \gets i + 1$
\EndWhile
\State \Return $x$
\EndFunction
\end{algorithmic}
\end{algorithm}
This algorithm trivially runs in linear time to the dimensionality $d$ of the input word $w$. For $n$ words of size $d$, this algorithm runs in $O(nd)$ time.
\citet{fast-similarity-search} presents two improvements to this: The first will improve the run time to $O(n\log(d))$ time by utilizing a divide-and-conquer technique and the second to $O(n + \log(d))$ time by introducing parallelism.
\subsubsection{Divide-and-Conquer}
To explain how divide-and-conquer methods can be used to improve run-time, we must first introduce a bit mask from \cite{fast-similarity-search} defined like so:
$$m_{i,j} = \underbrace{0\dots 0}_{2^{j}-2^{i}}\underbrace{1\dots 1}_{2^i}\dots\underbrace{0\dots 0}_{2^{j}-2^{i}}\underbrace{1\dots 1}_{2^i}$$
where $j > i$ and $j, i \in \mathbb{Z}^+$. The notation $m_{i}$ is a shorthand for $m_{i, i+1}$ and indicates a mask with an equal amount of 1's and 0's. By computing $w \land m_{i,j}$ for some word $w$ and some integers $i, j$, we can isolate a specific segments of size $2^i$ in the bitstring.
We will use this in the following operation:
\begin{equation}
    T(w, m, k) = (w\gg k) \land m
\end{equation}
This operation isolates the segments indicated by the bit-mask starting from the $k$th position of the word $w$.
The algorithm to calculate the cardinality can then be described like in algorithm \ref{alg:divide-and-conquer-cardinality}
\begin{algorithm}[H]
\caption{A divide-and-conquer approach}\label{alg:divide-and-conquer-cardinality}
\begin{algorithmic}
\Function{Cardinality}{$w$, $d$} \Comment{$w$ is the input word, $d$ is the word-size}
\State $i \gets 0$
\While{$i \leq \log_2(d)$}
\State $w \gets T(w, m_i, 0) + T(w, m_i, 2^i)$
\State $i \gets i + 1$
\EndWhile
\State \Return $w$
\EndFunction
\end{algorithmic}
\end{algorithm}
The simplest way to gain intuition of this algorithm is to prove it. A loop-invariant is presented like so:
\begin{invariant}
\label{thm:divide-invariant}
At the $i$th iteration of the algorithm, each bitstring-segment of size $2^i$ of the word $w_i$ will contain the cardinality of the corresponding segment of the word $w_0$. Furthermore, the operation can be done in constant time.
\end{invariant}
\begin{proof}
    When $i=0$, then each bit-string of size $2^0=1$ in $w_0 = w$ will be $1$ if the bit is $1$ and $0$ if the bit is $0$. This proves our base case. \\
    If at step $i$ the word $w_i$ contains $\frac{d}{2^i}$ segments of size $2^i$, then invariant \ref{thm:divide-invariant} will be upheld if we combine each segment with it's neighbor to form a segment of size $2^{i+1}$. Since the cardinality of a combined bitstring is equal to the cardinality of its parts, we can divide all of the segments into pairs of size $2^{i+1}$ and add them together to form the new pair, which is done by the operation $T(w, m_i, 0) + T(w, m_i, 2^i)$ in constant time if the masks are pre-computed. This operation works because $T(w, m_i, 0)$ isolates every other segment of size $2^i$ starting from the first segment and $T(w, m_i, 2^i)$ isolates every other segment of size $2^i$ starting from the second segment.\\
\end{proof}
When the algorithm terminates after $\log_2(d)$ iterations, the segments will have size $2^{\log_2{(d)}} = d$ and thus span the entire original word, which means that we have the bit-count of the original word. % TODO: Skriv noget omkring hvad der sker n√•r d ikke er en faktor af 2
\subsubsection{Parallelism}
To introduce parallelism into the algorithm, we must first realize the following: When two segments of $2^i$ bits gets combined, they will not need all of the $2^{i+1}$ bits to represent their sum. It is actually such that the bits used at iteration $i$ is exactly $i+1$.
\begin{invariant}
    At the $i$th iteration of the algorithm, the amount of bits set in a given segment of a word is at most $i+1$.
\end{invariant}
\begin{proof}
    We will prove this by induction. \\
    At $i=0$, the size of the segments are $2^0 = 1$, which is equal to $i+1$.\\
    If it is true at iteration $i$, then at iteration $i+1$ the algorithm will add two words of size $i+1$ which creates a word of size $i+2$, which fulfills the loop invariant.
\end{proof}
Now, we will introduce a function $l(i)$, which produces the smallest number such that $2^{l(i)} \geq i + 2$. If we use the bit mask $m_{l(i), i+1}$ instead of $m_{i}$, we will get the same result. This also means that we can pack $2^{i-l(i)}$ words into one by utilizing the empty space in each segment.
\begin{algorithm}[H]
\caption{A parallel divide-and-conquer algorithm}\label{alg:parallel-d-and-c}
    \begin{algorithmic}
        \Function{Compute}{$S$, $d$} \Comment{$S$ is the input set, $d$ is the word-size}
            \State $n \gets S.length$
            \For{$i \in [\log_2(d)]$}
                \State $k' \gets \{\}$
                \State $t \gets \{\}$
                \For{$w \in S$}
                    \State $k' \gets k' \cup \{T(w, m_i, 0) + T(w, m_i, 2^i)\}$
                \EndFor
                \If{$i < 2$}
                    \State $S \gets k'$
                \Else
                \If{$l(i) = l(i+1)$}
                    \For{$j \in [\lceil S.length / 2 \rceil]$}
                    \State $t \gets t \cup \{k'_{2j} + (k'_{2j+1} \ll 2^i)\}$ % TODO: Er det l(i) eller l(i+1)?
                    \EndFor
                \Else
                    \For{$j \in k'$}
                        \State $t \gets t \cup \{T(k'_{j}, m_{l(i)}, 0) + (T(k'_{j}, m_{l(i)}, 2^{l(i)}) \ll 2^{i})\}$
                    \EndFor
                \EndIf
                \State $S \gets t$
                \EndIf
            \EndFor
            \State $S' \gets \{\}$
            \For{$j$ in $[S.length]$} \Comment{For every word in the final set}
            \For{$k$ in $[2^{l(\log_2(d))}]$} \Comment{For every original word embedded in $S_j$}% TODO: Research this!
                \State $S' \gets S' \cup \{T(S_j, m_{l(\log_2(d)), \log_2(d) + 1}, k\cdot 2^{l(\log_2(d))})\}$
                \EndFor
            \EndFor
            \State \Return $S'$
        \EndFunction
    \end{algorithmic}
\end{algorithm}
This algorithm is quite a bit more complex than the first one, and to prove it we need some more terminology.\\
When we pack the words $t_0, \dots, t_{2^{i-l(i)}-1}$ into a word $t$, we say that $t$ is $i$-packed. This means one can extract all $2^{i-l(i)}$ different words by performing the operation:
\begin{equation}
    \label{eq:extract-from-embed}
t_j=T(t, m_{l(i), i+1}, j\cdot 2^{l(i)})
\end{equation}
for all $j\in [2^{i-l(i)}-1]$.
The point of the algorithm is to ensure that after every step of the algorithm that every word in $S$ is $(i+1)$ packed. When the first loop of the algorithm terminates at $i=\log_2(d)-1$, then every word will be $\log_2(d)$-packed, which means that it fits $2^{\log_2(d)-l(\log_2(d))}$ words. When working with 64-bit words, this will result in $2^{6-3}=8$ words per packed word.
\begin{invariant}
    At the end of the $i$th iteration of the first loop of the algorithm, every word in $S$ will be $(i+1)$-packed for any $i \geq 1$
\end{invariant}
\begin{proof}
    First, the first two iterations of the loop are run, such that $i=1$. During the first two iterations of the loop, no words are combined since it just uses the naive algorithm, which upholds the invariant because any $2$-packed words embeds $2^{0}=1$ of the original words.\\
    For any iteration where $i\geq 2$, one out of two things can happen. Either, $l(i+1) = l(i)$ (we do not need more bits to describe each segment), or $l(i + 1) = l(i) + 1$ (we need twice the amount of bits to describe each segment).\\
    In the first case, we will combine the words using bit-shifting. Since every word in $k'$ uses the same amount of bits to represent each segment even though we just combined segments when creating $k'$, there must be an empty space of at least size $l(i+1)$ in every segment. We can fill out that empty space by adding another word bit-shifted by a factor of 2. % TODO: Find ud af om det er 2^i eller 2^l(i)
    Now, the amount of words embedded is equal to the sum of both of its parts (i.e. has doubled). This upholds the loop invariant since any $(i+1)$-packed word must have twice the amount of words embedded than a $i$-packed word if $l(i+1) = l(i)$ by definition.\\
    In the second case, $l(i + 1) = l(i) + 1$. In this case, we need to relocate our segments that actually use $2^{l(i)}$ bits so they fit into the segments of size $2^i$ bits that were created when creating $k'$.
    The same amount of words have been embedded into each words as before, but as $l(i+1) = l(i) + 1$ a $(i+1)$-packed word should only embed the same amount of words as a $i$-packed word, which upholds the invariant.
    Furthermore, since we relocated the segments, we can now still extract each original word by performing the operation in equation \ref{eq:extract-from-embed}.\\
    The algorithm will terminate when $i = \log_2(d) - 1$, from which each word will embed $2^{\log_2(d)-l(\log_2(d))}$ of the original words.
\end{proof}

The second for loop of the algorithm extracts the cardinality of each of the original words by using equation \ref{eq:extract-from-embed}.\\
We can now move on to showing the run time of the algorithm. 
First, we can try to find the run time of the first for-loop. At each iteration $i$, we will describe the amount of elements in $S$ as $n_i$ with $n=n_0$. We can then describe $n_i$ like so:
\begin{equation}
    m_i=\lceil \frac{m}{2^{i-l(i)}} \rceil
\end{equation}
which means that the first for-loop in total takes
$$\sum_{i=2}^{\log_2(d)}\lceil \frac{m}{2^{i-l(i)}} \rceil$$
Since the last loop iterates over every element of the original set, it must take $O(m)$ time. We can now derive the total run time:
$$O(m) + \sum_{i=2}^{\log_2(d)}\lceil \frac{m}{2^{i-l(i)}} \rceil$$
$$=O(m) + \sum_{i=2}^{\log_2(d)}\lceil m2^{l(i)-i} \rceil$$
$$\leq O(m) + \sum_{i=2}^{\log_2(d)}(m2^{l(i)-i} + 1)$$
$$\leq O(m + \log(d)) + m\sum_{i=2}^{\log_2(d)}2^{l(i)-i}$$
Now we use the fact that $l(i)$ is always the smallest number that satisfies $2^{l(i)} \geq i + 2$. Since it is the smallest number, then $2^{l(i)} < 2(i+2)$, which can be proved by contradiction: $2^{l(i)} \geq 2(i+2) \implies 2^{l(i)-1} \geq i+2$, which shows that there is a number that is 1 smaller than $l(i)$ that upholds the bound $2^{l(i)} \geq i + 2$. Therefore $2^{l(i)} < 2(i+2)$. We can now use this fact:
$$\leq O(m + \log(d)) + m\sum_{i=0}^{\infty}\frac{2(i+2)}{2^{i}} = O(m+\log(d))$$
The run time of the algorithm can therefore be bound to $O(m + \log(d))$.
